# Copyright The OpenTelemetry Authors
# SPDX-License-Identifier: Apache-2.0

x-default-logging: &logging
  driver: "json-file"
  options:
    max-size: "5m"
    max-file: "2"
    tag: "{{.Name}}"

networks:
  default:
    name: opentelemetry-demo
    driver: bridge

services:
  # ******************
  # Core Demo Services
  # ******************
  # Accounting service
  accounting:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-accounting
    container_name: accounting
    build:
      context: ./
      dockerfile: ${ACCOUNTING_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-accounting
    deploy:
      resources:
        limits:
          memory: 160M
    restart: unless-stopped
    environment:
      - KAFKA_ADDR
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=accounting
      - DB_CONNECTION_STRING=Host=${POSTGRES_HOST};Username=otelu;Password=otelp;Database=${POSTGRES_DB}
      - OTEL_DOTNET_AUTO_TRACES_ENTITYFRAMEWORKCORE_INSTRUMENTATION_ENABLED=false
    depends_on:
      otel-collector:
        condition: service_started
      kafka:
        condition: service_healthy
    logging: *logging

  # AdService
  ad:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-ad
    container_name: ad
    build:
      context: ./
      dockerfile: ${AD_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-ad
      args:
        OTEL_JAVA_AGENT_VERSION: ${OTEL_JAVA_AGENT_VERSION}
    deploy:
      resources:
        limits:
          memory: 300M
    restart: unless-stopped
    ports:
      - "${AD_PORT}"
    environment:
      - AD_PORT
      - FLAGD_HOST
      - FLAGD_PORT
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_LOGS_EXPORTER=otlp
      - OTEL_SERVICE_NAME=ad
      # Workaround on OSX for https://bugs.openjdk.org/browse/JDK-8345296
      - _JAVA_OPTIONS
    depends_on:
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Cart service
  cart:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-cart
    container_name: cart
    build:
      context: ./
      dockerfile: ${CART_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-cart
    deploy:
      resources:
        limits:
          memory: 160M
    restart: unless-stopped
    ports:
      - "${CART_PORT}"
    environment:
      - CART_PORT
      - FLAGD_HOST
      - FLAGD_PORT
      - VALKEY_ADDR
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=cart
      - ASPNETCORE_URLS=http://*:${CART_PORT}
    depends_on:
      valkey-cart:
        condition: service_started
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Checkout service
  checkout:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-checkout
    container_name: checkout
    build:
      context: ./
      dockerfile: ${CHECKOUT_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-checkout
    deploy:
      resources:
        limits:
          memory: 20M
    restart: unless-stopped
    ports:
      - "${CHECKOUT_PORT}"
    environment:
      - FLAGD_HOST
      - FLAGD_PORT
      - CHECKOUT_PORT
      - CART_ADDR
      - CURRENCY_ADDR
      - EMAIL_ADDR
      - PAYMENT_ADDR
      - PRODUCT_CATALOG_ADDR
      - SHIPPING_ADDR
      - KAFKA_ADDR
      - GOMEMLIMIT=16MiB
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=checkout
    depends_on:
      cart:
        condition: service_started
      currency:
        condition: service_started
      email:
        condition: service_started
      payment:
        condition: service_started
      product-catalog:
        condition: service_started
      shipping:
        condition: service_started
      otel-collector:
        condition: service_started
      kafka:
        condition: service_healthy
      flagd:
        condition: service_started
    logging: *logging

  # Currency service
  currency:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-currency
    container_name: currency
    build:
      context: ./
      dockerfile: ${CURRENCY_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-currency
      args:
        OPENTELEMETRY_CPP_VERSION: ${OPENTELEMETRY_CPP_VERSION}
    deploy:
      resources:
        limits:
          memory: 20M
    restart: unless-stopped
    ports:
      - "${CURRENCY_PORT}"
    environment:
      - CURRENCY_PORT
      - IPV6_ENABLED
      - VERSION=${IMAGE_VERSION}
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=currency
    depends_on:
      otel-collector:
        condition: service_started
    logging: *logging

  # Email service
  email:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-email
    container_name: email
    build:
      context: ./
      dockerfile: ${EMAIL_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-email
    deploy:
      resources:
        limits:
          memory: 100M
    restart: unless-stopped
    ports:
      - "${EMAIL_PORT}"
    environment:
      - APP_ENV=production
      - EMAIL_PORT
      - FLAGD_HOST
      - FLAGD_PORT
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=email
    depends_on:
      otel-collector:
        condition: service_started
    logging: *logging

  # Fraud Detection service
  fraud-detection:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-fraud-detection
    container_name: fraud-detection
    build:
      context: ./
      dockerfile: ${FRAUD_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-fraud-detection
      args:
        OTEL_JAVA_AGENT_VERSION: ${OTEL_JAVA_AGENT_VERSION}
    deploy:
      resources:
        limits:
          memory: 300M
    restart: unless-stopped
    environment:
      - FLAGD_HOST
      - FLAGD_PORT
      - KAFKA_ADDR
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_INSTRUMENTATION_KAFKA_EXPERIMENTAL_SPAN_ATTRIBUTES=true
      - OTEL_INSTRUMENTATION_MESSAGING_EXPERIMENTAL_RECEIVE_TELEMETRY_ENABLED=true
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=fraud-detection
    depends_on:
      otel-collector:
        condition: service_started
      kafka:
        condition: service_healthy
    logging: *logging

  # Frontend
  frontend:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-frontend
    container_name: frontend
    build:
      context: ./
      dockerfile: ${FRONTEND_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-frontend
    deploy:
      resources:
        limits:
          memory: 250M
    restart: unless-stopped
    ports:
      - "${FRONTEND_PORT}"
    environment:
      - PORT=${FRONTEND_PORT}
      - FRONTEND_ADDR
      - AD_ADDR
      - CART_ADDR
      - CHECKOUT_ADDR
      - CURRENCY_ADDR
      - PRODUCT_CATALOG_ADDR
      - PRODUCT_REVIEWS_ADDR
      - RECOMMENDATION_ADDR
      - SHIPPING_ADDR
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_RESOURCE_ATTRIBUTES
      - ENV_PLATFORM
      - OTEL_SERVICE_NAME=frontend
      - PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - WEB_OTEL_SERVICE_NAME=frontend-web
      - OTEL_COLLECTOR_HOST
      - FLAGD_HOST
      - FLAGD_PORT
    depends_on:
      ad:
        condition: service_started
      cart:
        condition: service_started
      checkout:
        condition: service_started
      currency:
        condition: service_started
      product-catalog:
        condition: service_started
      quote:
        condition: service_started
      recommendation:
        condition: service_started
      shipping:
        condition: service_started
      otel-collector:
        condition: service_started
      image-provider:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Frontend Proxy (Envoy)
  frontend-proxy:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-frontend-proxy
    container_name: frontend-proxy
    build:
      context: ./
      dockerfile: ${FRONTEND_PROXY_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-frontend-proxy
    deploy:
      resources:
        limits:
          memory: 65M
    restart: unless-stopped
    ports:
      - "${ENVOY_PORT}:${ENVOY_PORT}"
      - "${ENVOY_ADMIN_PORT}:${ENVOY_ADMIN_PORT}"
    environment:
      - FRONTEND_PORT
      - FRONTEND_HOST
      - LOCUST_WEB_HOST
      - LOCUST_WEB_PORT
      - GRAFANA_PORT
      - GRAFANA_HOST
      - JAEGER_UI_PORT
      - JAEGER_HOST
      - OTEL_COLLECTOR_HOST
      - IMAGE_PROVIDER_HOST
      - IMAGE_PROVIDER_PORT
      - OTEL_COLLECTOR_PORT_GRPC
      - OTEL_COLLECTOR_PORT_HTTP
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=frontend-proxy
      - ENVOY_PORT
      - ENVOY_ADDR
      - ENVOY_ADMIN_PORT
      - FLAGD_HOST
      - FLAGD_PORT
      - FLAGD_UI_HOST
      - FLAGD_UI_PORT
    depends_on:
      frontend:
        condition: service_started
      load-generator:
        condition: service_started
      jaeger:
        condition: service_started
      grafana:
        condition: service_started
      flagd-ui:
        condition: service_started
    dns_search: ""

  # image-provider
  image-provider:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-image-provider
    container_name: image-provider
    build:
      context: ./
      dockerfile: ${IMAGE_PROVIDER_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-image-provider
    deploy:
      resources:
        limits:
          memory: 120M
    restart: unless-stopped
    ports:
      - "${IMAGE_PROVIDER_PORT}"
    environment:
      - IMAGE_PROVIDER_PORT
      - OTEL_COLLECTOR_HOST
      - OTEL_COLLECTOR_PORT_GRPC
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=image-provider
    depends_on:
      otel-collector:
        condition: service_started
    logging: *logging

  # Load Generator
  load-generator:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-load-generator
    container_name: load-generator
    build:
      context: ./
      dockerfile: ${LOAD_GENERATOR_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-load-generator
    deploy:
      resources:
        limits:
          memory: 1500M
    restart: unless-stopped
    ports:
      - "${LOCUST_WEB_PORT}"
    environment:
      - LOCUST_WEB_PORT
      - LOCUST_USERS
      - LOCUST_HOST
      - LOCUST_HEADLESS
      - LOCUST_AUTOSTART
      - LOCUST_BROWSER_TRAFFIC_ENABLED=true
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=load-generator
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
      - LOCUST_WEB_HOST=0.0.0.0
      - FLAGD_HOST
      - FLAGD_PORT
      - FLAGD_OFREP_PORT
    depends_on:
      frontend:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Payment service
  payment:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-payment
    container_name: payment
    build:
      context: ./
      dockerfile: ${PAYMENT_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-payment
    deploy:
      resources:
        limits:
          memory: 140M
    restart: unless-stopped
    ports:
      - "${PAYMENT_PORT}"
    environment:
      - IPV6_ENABLED
      - PAYMENT_PORT
      - FLAGD_HOST
      - FLAGD_PORT
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=payment
    depends_on:
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Product Catalog service
  product-catalog:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-product-catalog
    container_name: product-catalog
    build:
      context: ./
      dockerfile: ${PRODUCT_CATALOG_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-product-catalog
    deploy:
      resources:
        limits:
          memory: 20M
    restart: unless-stopped
    ports:
      - "${PRODUCT_CATALOG_PORT}"
    environment:
      - PRODUCT_CATALOG_PORT
      - PRODUCT_CATALOG_RELOAD_INTERVAL
      - FLAGD_HOST
      - FLAGD_PORT
      - GOMEMLIMIT=16MiB
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=product-catalog
    volumes:
      - ./src/product-catalog/products:/usr/src/app/products
    depends_on:
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Product reviews service
  product-reviews:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-product-reviews
    container_name: product-reviews
    build:
      context: ./
      dockerfile: ${PRODUCT_REVIEWS_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-product-reviews
    deploy:
      resources:
        limits:
          memory: 100M
    restart: unless-stopped
    ports:
      - "${PRODUCT_REVIEWS_PORT}"
    environment:
      - PRODUCT_REVIEWS_PORT
      - OTEL_PYTHON_LOG_CORRELATION=true
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=product-reviews
      - OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=true
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
      - DB_CONNECTION_STRING=host=${POSTGRES_HOST} user=otelu password=otelp dbname=${POSTGRES_DB}
      - LLM_BASE_URL
      - OPENAI_API_KEY
      - LLM_MODEL
      - PRODUCT_CATALOG_ADDR
      - FLAGD_HOST
      - FLAGD_PORT
      - LLM_HOST
      - LLM_PORT
    depends_on:
      product-catalog:
        condition: service_started
      llm:
        condition: service_started
      postgresql:
        condition: service_started
      otel-collector:
        condition: service_started
    logging: *logging

  # Quote service
  quote:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-quote
    container_name: quote
    build:
      context: ./
      dockerfile: ${QUOTE_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-quote
    deploy:
      resources:
        limits:
          memory: 40M
    restart: unless-stopped
    ports:
      - "${QUOTE_PORT}"
    environment:
      - IPV6_ENABLED
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_PHP_AUTOLOAD_ENABLED=true
      - QUOTE_PORT
      - OTEL_PHP_INTERNAL_METRICS_ENABLED=true
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=quote
    depends_on:
      otel-collector:
        condition: service_started
    logging: *logging

  # Recommendation service
  recommendation:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-recommendation
    container_name: recommendation
    build:
      context: ./
      dockerfile: ${RECOMMENDATION_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-recommendation
    deploy:
      resources:
        limits:
          memory: 500M               # This is high to enable supporting the recommendationCache feature flag use case
    restart: unless-stopped
    ports:
      - "${RECOMMENDATION_PORT}"
    environment:
      - RECOMMENDATION_PORT
      - PRODUCT_CATALOG_ADDR
      - FLAGD_HOST
      - FLAGD_PORT
      - OTEL_PYTHON_LOG_CORRELATION=true
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=recommendation
      - PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
    depends_on:
      product-catalog:
        condition: service_started
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    logging: *logging

  # Shipping service
  shipping:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-shipping
    container_name: shipping
    build:
      context: ./
      dockerfile: ${SHIPPING_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-shipping
    deploy:
      resources:
        limits:
          memory: 20M
    restart: unless-stopped
    ports:
      - "${SHIPPING_PORT}"
    environment:
      - IPV6_ENABLED
      - SHIPPING_PORT
      - QUOTE_ADDR
      - OTEL_EXPORTER_OTLP_ENDPOINT
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=shipping
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
    depends_on:
      otel-collector:
        condition: service_started
    logging: *logging

  # ******************
  # Dependent Services
  # ******************
  # Flagd, feature flagging service
  flagd:
    image: ${FLAGD_IMAGE}
    container_name: flagd
    deploy:
      resources:
        limits:
          memory: 75M
    restart: unless-stopped
    environment:
      - FLAGD_OTEL_COLLECTOR_URI=${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_GRPC}
      - FLAGD_METRICS_EXPORTER=otel
      - GOMEMLIMIT=60MiB
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=flagd
    command: [
      "start",
      "--uri",
      "file:./etc/flagd/demo.flagd.json"
    ]
    ports:
      - "${FLAGD_PORT}"
      - "${FLAGD_OFREP_PORT}"
    volumes:
      - ./src/flagd:/etc/flagd
    logging:
      *logging

  # Flagd UI for configuring the feature flag service
  flagd-ui:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-flagd-ui
    container_name: flagd-ui
    build:
      context: ./
      dockerfile: ${FLAGD_UI_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-flagd-ui
    deploy:
      resources:
        limits:
          memory: 200M
    restart: always
    environment:
      - FLAGD_UI_PORT
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=flagd-ui
      - SECRET_KEY_BASE=yYrECL4qbNwleYInGJYvVnSkwJuSQJ4ijPTx5tirGUXrbznFIBFVJdPl5t6O9ASw
      - PHX_HOST=localhost
    ports:
      - "${FLAGD_UI_PORT}"
    depends_on:
      otel-collector:
        condition: service_started
      flagd:
        condition: service_started
    volumes:
      - ./src/flagd:/app/data

  # Kafka used by Checkout, Accounting, and Fraud Detection services
  kafka:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-kafka
    container_name: kafka
    build:
      context: ./
      dockerfile: ${KAFKA_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-kafka
      args:
        OTEL_JAVA_AGENT_VERSION: ${OTEL_JAVA_AGENT_VERSION}
    deploy:
      resources:
        limits:
          memory: 620M
    restart: unless-stopped
    environment:
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://${KAFKA_HOST}:9092
      - KAFKA_LISTENERS=PLAINTEXT://${KAFKA_HOST}:9092,CONTROLLER://${KAFKA_HOST}:9093
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@${KAFKA_HOST}:9093
      - OTEL_EXPORTER_OTLP_ENDPOINT=http://${OTEL_COLLECTOR_HOST}:${OTEL_COLLECTOR_PORT_HTTP}
      - OTEL_EXPORTER_OTLP_METRICS_TEMPORALITY_PREFERENCE
      - OTEL_RESOURCE_ATTRIBUTES
      - OTEL_SERVICE_NAME=kafka
      - KAFKA_HEAP_OPTS=-Xmx400m -Xms400m
      # Workaround on OSX for https://bugs.openjdk.org/browse/JDK-8345296
      - _JAVA_OPTIONS
    healthcheck:
      test: nc -z kafka 9092
      start_period: 10s
      interval: 5s
      timeout: 10s
      retries: 10
    logging: *logging

  # LLM used by Product Review service
  llm:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-llm
    container_name: llm
    build:
      context: ./
      dockerfile: ${LLM_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-llm
    deploy:
      resources:
        limits:
          memory: 50M
    restart: unless-stopped
    environment:
      - FLAGD_HOST
      - FLAGD_PORT
    ports:
      - "${LLM_PORT}"
    depends_on:
      flagd:
        condition: service_started
    logging: *logging

  # Postgresql used by Accounting service
  postgresql:
    image: ${IMAGE_NAME}:${DEMO_VERSION}-postgresql
    container_name: postgresql
    build:
      context: ./
      dockerfile: ${POSTGRES_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-postgresql
    deploy:
      resources:
        limits:
          memory: 80M
    restart: unless-stopped
    ports:
      - ${POSTGRES_PORT}
    environment:
      - POSTGRES_USER=root
      - POSTGRES_PASSWORD
      - POSTGRES_DB
    logging: *logging

  # Valkey used by Cart service
  valkey-cart:
    image: ${VALKEY_IMAGE}
    container_name: valkey-cart
    user: valkey
    deploy:
      resources:
        limits:
          memory: 20M
    restart: unless-stopped
    ports:
      - "${VALKEY_PORT}"
    logging: *logging


  # ********************
  # Telemetry Components
  # ********************
  # Jaeger
  jaeger:
    image: ${JAEGERTRACING_IMAGE}
    container_name: jaeger
    command:
      - "--config=file:/etc/jaeger/config.yml"
    deploy:
      resources:
        limits:
          memory: 1200M
    restart: unless-stopped
    ports:
      - "${JAEGER_UI_PORT}"
      - "${JAEGER_GRPC_PORT}"
    environment:
      - JAEGER_HOST
      - JAEGER_GRPC_PORT
      - PROMETHEUS_ADDR
      - OTEL_COLLECTOR_HOST
      - OTEL_COLLECTOR_PORT_HTTP
      - MEMORY_MAX_TRACES=25000
    volumes:
      - ./src/jaeger/config.yml:/etc/jaeger/config.yml
    logging: *logging

  # Grafana
  grafana:
    image: ${GRAFANA_IMAGE}
    container_name: grafana
    deploy:
      resources:
        limits:
          memory: 175M
    restart: unless-stopped
    environment:
    #  - "GF_INSTALL_PLUGINS=grafana-opensearch-datasource"
    # disabled plugin installation due to Zscaler problem; container cannot call https to the plugin repository due to unknown certificate authority
    # plugin is downloaded manually and mounted into the container
    - GF_FEATURE_TOGGLES_ENABLE=traceqlEditor metricsSummary
    volumes:
      - ./src/grafana/grafana.ini:/etc/grafana/grafana.ini
      - ./src/grafana/provisioning/:/etc/grafana/provisioning/
      - ./src/grafana/plugins/:/var/lib/grafana/plugins
    ports:
      - "${GRAFANA_PORT}"
    logging: *logging

  # OpenTelemetry Collector
  otel-collector:
    image: ${COLLECTOR_CONTRIB_IMAGE}
    container_name: otel-collector
    deploy:
      resources:
        limits:
          memory: 200M
    restart: unless-stopped
    command: [ "--config=/etc/otelcol-config.yml", "--config=/etc/otelcol-config-extras.yml" ]
    user: 0:0
    volumes:
      - ${HOST_FILESYSTEM}:/hostfs:ro
      - ${DOCKER_SOCK}:/var/run/docker.sock:ro
      - ${OTEL_COLLECTOR_CONFIG}:/etc/otelcol-config.yml
      - ${OTEL_COLLECTOR_CONFIG_EXTRAS}:/etc/otelcol-config-extras.yml
    ports:
      - "${OTEL_COLLECTOR_PORT_GRPC}"
      - "${OTEL_COLLECTOR_PORT_HTTP}"
    depends_on:
      jaeger:
        condition: service_started
      opensearch:
        condition: service_healthy
    logging: *logging
    environment:
      - FRONTEND_PROXY_ADDR
      - IMAGE_PROVIDER_HOST
      - IMAGE_PROVIDER_PORT
      - HOST_FILESYSTEM
      - OTEL_COLLECTOR_HOST
      - OTEL_COLLECTOR_PORT_GRPC
      - OTEL_COLLECTOR_PORT_HTTP
      - POSTGRES_HOST
      - POSTGRES_PORT
      - POSTGRES_PASSWORD
      - GOMEMLIMIT=160MiB

  # Prometheus
  prometheus:
    image: ${PROMETHEUS_IMAGE}
    container_name: prometheus
    command:
      - --web.console.templates=/etc/prometheus/consoles
      - --web.console.libraries=/etc/prometheus/console_libraries
      - --storage.tsdb.retention.time=7d
      - --config.file=/etc/prometheus/prometheus-config.yaml
      - --storage.tsdb.path=/prometheus
      - --web.enable-lifecycle
      - --web.route-prefix=/
      - --web.enable-otlp-receiver
      - --enable-feature=exemplar-storage
      - --web.enable-remote-write-receiver
      - --enable-feature=native-histograms
    volumes:
      - ./src/prometheus/prometheus-config.yaml:/etc/prometheus/prometheus-config.yaml
    deploy:
      resources:
        limits:
          memory: 200M
    restart: unless-stopped
    ports:
      - "${PROMETHEUS_PORT}:${PROMETHEUS_PORT}"
    logging: *logging

  # OpenSearch
  opensearch:
    container_name: opensearch
    build:
      context: ./
      dockerfile: ${OPENSEARCH_DOCKERFILE}
      cache_from:
        - ${IMAGE_NAME}:${IMAGE_VERSION}-opensearch
    deploy:
      resources:
        limits:
          memory: 1G
    restart: unless-stopped
    environment:
      - cluster.name=demo-cluster
      - node.name=demo-node
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      - OPENSEARCH_JAVA_OPTS=-Xms400m -Xmx400m
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - DISABLE_SECURITY_PLUGIN=true
      # Workaround on OSX for https://bugs.openjdk.org/browse/JDK-8345296
      - _JAVA_OPTIONS
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "9200"
    healthcheck:
      test: curl -s http://localhost:9200/_cluster/health | grep -E '"status":"(green|yellow)"'
      start_period: 30s
      interval: 5s
      timeout: 15s
      retries: 20
    volumes:
      - ./data/opensearch:/usr/share/opensearch/data:Z,U  
    logging: *logging
  opensearch-dashboards:
    image: opensearchproject/opensearch-dashboards:3.1.0
    container_name: opensearch-dashboards
    ports:
      - 5601:5601
    expose:
      - '5601'
    environment:
      OPENSEARCH_HOSTS: '["http://opensearch:9200"]'
      DISABLE_SECURITY_DASHBOARDS_PLUGIN: 'true'

  clickhouse-server:
    # image: clickhouse/clickhouse-server:24.9.1-alpine
    image: clickhouse/clickhouse-server:25.3.6.56-alpine
    container_name: clickhouse-server
    hostname: clickhouse
    restart: unless-stopped
    volumes:
      - clickhouse_data:/var/lib/clickhouse
      # using bind mount to local filesystem leads to file rename errors inside container- ./data/clickhouse:/var/lib/clickhouse:Z,rw
      - ./data/logs/clickhouse:/var/log/clickhouse-server:Z,U
      - ./src/clickhouse/opentelemetry_zipkin.sql:/docker-entrypoint-initdb.d/opentelemetry_zipkin.sql
    environment:
      - CLICKHOUSE_USER=gigapipe
      - CLICKHOUSE_PASSWORD=demo
    ulimits:
      nofile: # see --ulimit nofile=262144:262144 in https://hub.docker.com/r/clickhouse/clickhouse-server/
        soft: 262144
        hard: 262144
    # according to https://clickhouse.com/docs/knowledgebase/configure_cap_ipc_lock_and_cap_sys_nice_in_docker
    cap_add:
      - IPC_LOCK
      - SYS_NICE
    privileged: true      

    ports:
      - 8123:8123
      - 9000:9000
    healthcheck:
      test: ['CMD', 'wget', '--spider', '-q', '127.0.0.1:8123/ping']
      interval: 1s
      timeout: 1s
      retries: 30
    logging:
      driver: "local"
      options:
        max-size: "10m"
        max-file: "5"

  gigapipe:
    #image: ghcr.io/metrico/gigapipe:latest
    #pull_policy: always
    image: ghcr.io/metrico/gigapipe:v4.0.17
    container_name: gigapipe
    hostname: gigapipe
    restart: unless-stopped
    expose:
      - 3100
    ports:
      - "3100:3100"
    environment:
      - CLICKHOUSE_SERVER=clickhouse-server
      - CLICKHOUSE_PORT=9000
      - CLICKHOUSE_AUTH=gigapipe:demo
      - CLICKHOUSE_DB=qryn
      - PORT=3100
      - NODE_OPTIONS="--max-old-space-size=4096"
      - FASTIFY_METRICS=true
    depends_on:
      clickhouse-server:
        condition: service_healthy
    logging:
      driver: "local"
      options:
        max-size: "10m"
        max-file: "5"

  # otel-collector-qryn:
  #   container_name: otel-collector-qryn
  #   hostname: otel-collector-qryn
  #   image: ghcr.io/metrico/qryn-otel-collector:latest

  #   volumes:
  #     - ./src/otel-collector-qryn/otel-collector-qryn-config.yaml:/etc/otel/config.yaml
  #   ports:
  #     - "4317:4317"     # OTLP gRPC receiver
  #     - "4318:4318"     # OTLP HTTP receiver
  #   restart: on-failure

  memcached:
    image: memcached:1.6.38
    container_name: memcached
    ports:
      - "11211:11211"
    environment:
      - MEMCACHED_MAX_MEMORY=64m # Set the maximum memory usage
      - MEMCACHED_THREADS=4 # Number of threads to use

  tempo:
    image: grafana/tempo:2.8.1
    container_name: tempo
    restart: on-failure
    command: ["-config.file=/etc/tempo.yaml"]
    volumes:
      - ./src/tempo/tempo.yaml:/etc/tempo.yaml
      - tempo_data:/var/tempo
    ports:
      - "3200:3200" # tempo
      - "9095:9095" # tempo grpc
      - "14317:4317" # otlp grpc
      - "14318:4318" # otlp http

    depends_on:
      - memcached    
volumes:
    clickhouse_data: {}       
    tempo_data: {}
